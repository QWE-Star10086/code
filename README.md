1. 单词识别与分割规则
分隔符定义：仅以空格作为单词的分割标志（包括空格、制表符 \t、换行符 \n 等空白字符）。
连字符处理：连字符（-）连接的字符序列视为单个单词（例如 "state-of-the-art" 会被完整统计为一个词）。
数字处理：纯数字序列（如 "2023"、"10.5"）或包含数字的字符串（如 "page123"）会被视为有效单词并统计。
空字符串过滤：去除标点后若为空字符串（如 "!!!"" 处理后为空），则不纳入统计。
2. 大小写处理规则
所有单词会被统一转换为小写后统计（例如 "Hello"、"HELLO"、"hello" 会被视为同一个词）。
输出结果中的单词以小写形式展示（即使原文本中是大写）。
3. 标点符号处理范围
自动移除所有标准标点符号（基于 Python string.punctuation 定义），包括：
!"#$%&'()*+,-./:;<=>?@[\]^_{|}~`
未处理的符号：特殊 Unicode 标点（如 “”‘’、《》、「」）、emoji 符号（如 😊、🔥）、非英文标点（如 ¡、¿）可能无法完全去除，可能导致统计偏差（例如 "hello😊" 会被视为 "hello😊" 而非 "hello"）。
4. 编码与文件类型限制
编码要求：仅支持 UTF-8 编码的文本文件，其他编码（如 GBK、ISO-8859-1）可能导致读取错误或乱码，进而影响统计结果。
文件类型限制：仅能处理纯文本文件（.txt 等），对二进制文件（如 .pdf、.doc、图片、音频）会读取失败或产生无意义结果。
5. 语言适配性限制
主要针对空格分隔的语言（如英语、法语、德语）设计，可正常分词。
对无空格分隔的语言（如中文、日语、韩语、泰语）分词效果极差（会将整段文本视为一个或少数几个 “单词”）。
6. 极端情况处理逻辑
空文件或无有效单词：输出空的结果列表（仅显示标题和分隔线）。
单词总数不足 20 个：按实际数量输出所有统计到的单词（例如只有 5 个不同单词时，仅显示这 5 个）。
超大文件：会一次性加载到内存处理，若文件过大（如超过 100MB）可能导致内存占用过高或运行缓慢。
重复单词过多：仅输出词频最高的前 20 个单词（即使总词数超过 20）。
